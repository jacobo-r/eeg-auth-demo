{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util.data_loader import PhysioDataset\n",
    "from util.transforms import filterBank\n",
    "from torch.utils.data import DataLoader\n",
    "from model.mixed_fbcnet import MIXED_FBCNet\n",
    "from torch import nn\n",
    "from torch.optim import lr_scheduler\n",
    "from sklearn.metrics import det_curve\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the data loader and most code provided by the paper:\n",
    "\n",
    "\"Towards Enhanced EEG-based Authentication with Motor Imagery Brain-Computer Interface\" by Bingkun Wu et al.\n",
    "\n",
    "https://dl.acm.org/doi/abs/10.1145/3564625.3564656"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load the intra test data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's the link for the dataset:\n",
    "\n",
    "https://physionet.org/content/eegmmidb/1.0.0/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure you download and install the dataset such that it can be accesible through a path that you define here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path=\"./data/physionet/physionet.org/files/eegmmidb/1.0.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "filterTransform = filterBank([[4,8],[8,12],[12,16],[16,20],[20,24],[24,28],[28,32],[32,36],[36,40]], 160) # frequency bands\n",
    "    \n",
    "batch_size = 4\n",
    "        \n",
    "channels =  [9, 14, 15, 16, 17, 18, 19, 21, 22, 62] # electrodes\n",
    "\n",
    "subject = 3\n",
    "\n",
    "intra_test_data = PhysioDataset(subject=subject, path=path, train=\"intra_test\", transform=filterTransform, channels=channels, preprocess=False)\n",
    "\n",
    "intra_test_dataloader = DataLoader(intra_test_data, batch_size=batch_size, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We wan to use the Intra test data set as it contains attackers that the system is already familiar with (also known as inside attackers).\n",
    "\n",
    "By design, this dataset contains bona fide samples from the subject for which the model was trained (here set to subject 3), as well as sample from other subjects as attackers.\n",
    "\n",
    "To see more details on this dataset, please check the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "util.data_loader.PhysioDataset"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(intra_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([125, 10, 640, 9])\n",
      "torch.Size([125])\n"
     ]
    }
   ],
   "source": [
    "# Collect all samples and labels from the dataloader\n",
    "all_samples = []\n",
    "all_labels = []\n",
    "\n",
    "for samples, labels in intra_test_data:\n",
    "    all_samples.append(samples.unsqueeze(0))  # Add an extra batch dimension\n",
    "    all_labels.append(labels)\n",
    "\n",
    "# Convert lists to tensors\n",
    "samples = torch.cat(all_samples, dim=0)\n",
    "labels = torch.tensor(all_labels, dtype=torch.long)\n",
    "\n",
    "# Printing the shapes to verify\n",
    "print(samples.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The label 1 means bona fide and 0 means attacker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([125, 10, 640, 9])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples.shape # each sample has 10 channels, 640 samples and 9 frequency bands, therefore this should be 125x10x640x9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Load the pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path= \"./trained/3_99.2_98.4_20.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MIXED_FBCNet(\n",
       "  (channelProj): Sequential(\n",
       "    (0): Conv2dWithConstraint(10, 30, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): swish()\n",
       "  )\n",
       "  (shapeTrans): Sequential(\n",
       "    (0): Conv2dWithConstraint(30, 30, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): swish()\n",
       "  )\n",
       "  (spatialConv): Sequential(\n",
       "    (0): Conv2dWithConstraint(9, 288, kernel_size=(10, 1), stride=(1, 1), groups=9)\n",
       "    (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): swish()\n",
       "  )\n",
       "  (pointWise): Sequential(\n",
       "    (0): Conv2dWithConstraint(288, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): swish()\n",
       "  )\n",
       "  (varLayer): LogVarLayer()\n",
       "  (standTemporalLayer): Sequential(\n",
       "    (0): Dropout2d(p=0.5, inplace=False)\n",
       "    (1): Conv2dWithConstraint(288, 28, kernel_size=(1, 32), stride=(32, 32), bias=False)\n",
       "    (2): BatchNorm2d(28, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): swish()\n",
       "    (4): MaxPool2d(kernel_size=(1, 4), stride=4, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.5, inplace=False)\n",
       "    (1): Conv2dWithConstraint(316, 316, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (2): BatchNorm2d(316, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (lastLayer): Sequential(\n",
       "    (0): LinearWithConstraint(in_features=1580, out_features=2, bias=True)\n",
       "    (1): LogSoftmax(dim=1)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MIXED_FBCNet(nChan=10, nBands=9) #class where the model is defined.\n",
    "model.load_state_dict(torch.load(model_path)) # Load the weights\n",
    "model.eval() # Set the model to evaluation mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Using the trained model to authenticate \"Bona Fide\" vs \"Attacker\" Scenarios (DEMO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is where we would use newly recorded data from an EEG device in order to test the strenght of our security system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "attacker = samples[50] # I jus took a sample for which the label was 0\n",
    "bona_fide= samples[0] # same but here the label is 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw output: tensor([[-3.5089e-04, -7.9551e+00]])\n",
      "Predicted class: 0\n",
      "--- Authentication Failed ---\n"
     ]
    }
   ],
   "source": [
    "# Predict the class of the Attacker:\n",
    "with torch.no_grad():\n",
    "    output = model(attacker.unsqueeze(0))\n",
    "\n",
    "print(f\"Raw output: {output}\")\n",
    "\n",
    "# Convert raw output to predicted class index\n",
    "predicted_class = output.argmax(dim=1)\n",
    "\n",
    "print(f\"Predicted class: {predicted_class.item()}\")\n",
    "\n",
    "print(\"--- Authentication Successful ---\" if predicted_class.item() else \"--- Authentication Failed ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
